# 데카트론 AI 챗봇 실행 가이드

이 문서는 데카트론 AI 챗봇 프로젝트를 로컬 환경에서 설정하고 실행하는 상세한 방법을 단계별로 안내합니다. **모든 명령어는 특별한 언급이 없는 한, 프로젝트의 최상위 디렉토리(`chatbot/`)에서 실행하는 것을 기준으로 합니다.**

## 1. 환경 준비

### 1.1. Python 설치 확인

* 이 프로젝트는 **Python 3.11** 버전에서 개발되었습니다. 터미널(명령 프롬프트)에서 아래 명령어로 버전을 확인하세요.
    ```bash
    python --version
    # 또는 python3 --version
    ```
* Python 3.11이 설치되어 있지 않다면, [python.org](https://www.python.org/) 공식 웹사이트에서 다운로드하여 설치해 주십시오. (`requirements.txt` 파일에서 정확한 라이브러리 버전을 확인할 수 있습니다.)

### 1.2. Git 설치 및 프로젝트 클론

* Git 버전 관리 시스템이 설치되어 있는지 확인하고, 설치되어 있지 않다면 [git-scm.com](https://git-scm.com/)에서 다운로드하여 설치해 주십시오.
* 프로젝트를 로컬 머신으로 복제(클론)합니다.
    ```bash
    git clone <저장소_URL>
    cd chatbot # 클론된 프로젝트 디렉토리로 이동합니다.
    ```

### 1.3. 가상 환경 생성 및 활성화 (권장)

프로젝트별 의존성 충돌을 방지하기 위해 파이썬 가상 환경 사용을 강력히 권장합니다.

* **가상 환경 생성 (프로젝트 루트에서 실행):**
    ```bash
    python -m venv venv
    # 또는 python3 -m venv venv
    ```
* **가상 환경 활성화:**
    * Linux / macOS:
        ```bash
        source venv/bin/activate
        ```
    * Windows (Command Prompt):
        ```bash
        venv\Scripts\activate.bat
        ```
    * Windows (PowerShell):
        ```bash
        venv\Scripts\Activate.ps1
        ```
        *(참고: PowerShell에서 스크립트 실행 정책 오류가 발생하면, `Set-ExecutionPolicy Unrestricted -Scope Process` 명령어를 먼저 실행한 후 다시 시도해 보세요.)*
* 가상 환경이 성공적으로 활성화되면, 터미널 프롬프트 시작 부분에 `(venv)`와 같이 표시됩니다.

## 2. 의존성 설치

프로젝트 실행에 필요한 Python 라이브러리들을 설치합니다. **가상 환경이 활성화된 상태**에서 아래 명령어를 실행하세요.

```bash
pip install -r requirements.txt
```

* 이 명령은 `requirements.txt` 파일에 명시된 모든 라이브러리를 자동으로 설치합니다.

## 3. OpenAI API 키 설정

챗봇이 OpenAI 모델(GPT, Embedding)을 사용하기 위해 API 키 설정이 필수적입니다.

1.  프로젝트 루트 디렉토리에 있는 `.env.example` 파일을 복사하고, 복사본의 이름을 `.env`로 변경합니다.
2.  생성된 `.env` 파일을 텍스트 편집기로 엽니다.
3.  파일 내용 중 `OPENAI_API_KEY=` 뒷부분에 **자신의 OpenAI API 키**를 **따옴표 없이** 입력하고 파일을 저장합니다.
    ```dotenv
    # .env 파일 내용 예시:
    OPENAI_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
    ```
    * API 키는 OpenAI 웹사이트에서 발급받을 수 있습니다. 이 키는 외부에 노출되지 않도록 주의해야 합니다.

## 4. RAG 인덱스 생성 (오프라인 파이프라인)

챗봇의 RAG(Retrieval-Augmented Generation) 기능을 사용하기 위해서는, 기반 문서로부터 벡터 인덱스를 생성하는 사전 작업이 필요합니다. **이 단계는 챗봇 서버 실행 전에 반드시 성공적으로 완료되어야 RAG 기능이 정상 동작합니다.**

1.  **(선택) 원본 데이터 확인/추가:**
    * `data/original/` 디렉토리에 RAG의 기반이 될 정보 파일(`.txt`)들이 위치합니다. 샘플 파일을 확인하거나, 필요한 자체 문서(반드시 **UTF-8 인코딩**)를 추가할 수 있습니다.
2.  **파이프라인 스크립트 실행:**
    * 프로젝트 루트 디렉토리에서 아래 명령어를 실행하여 인덱스 생성을 시작합니다.
        ```bash
        python pipeline/rag_generator.py
        ```
    * 콘솔에 문서 로딩, 텍스트 분할, 임베딩 생성 (배치 처리), FAISS 인덱스 빌드 과정이 출력됩니다.
    * **주의:** 이 과정은 **OpenAI Embedding API를 호출하여 비용이 발생**하며, 문서 양에 따라 **상당한 시간(수 분 ~ 수십 분 이상)이 소요**될 수 있습니다.
3.  **결과 확인:**
    * 스크립트 실행이 오류 없이 완료되면, `data/` 디렉토리 내에 `index.faiss` (벡터 인덱스 파일)와 `doc_meta.jsonl` (문서 조각 및 메타데이터 파일)이 생성됩니다.
    * 만약 이 과정에서 오류가 발생하면, 로그를 확인하여 원인을 파악하고 해결해야 합니다. 오류 발생 시 챗봇 서버는 실행될 수 있으나 RAG 기능은 비활성화됩니다.

## 5. 챗봇 서버 실행

모든 설정과 RAG 인덱스 생성이 완료되었다면, 챗봇 웹 서버를 실행할 준비가 되었습니다.

1.  프로젝트 루트 디렉토리에서 아래 명령어를 실행합니다.
    ```bash
    uvicorn chatbot.app:app --host 127.0.0.1 --port 8000
    ```
    * `chatbot.app:app`: `chatbot` 패키지 내 `app.py` 파일의 `app` FastAPI 인스턴스를 실행합니다.
    * `--host 127.0.0.1`: 로컬 컴퓨터에서만 접속을 허용합니다.
    * `--port 8000`: 챗봇 서버가 8000번 포트를 사용하도록 지정합니다.
2.  서버가 성공적으로 시작되면, 터미널에 `Uvicorn running on http://127.0.0.1:8000` 와 같은 메시지가 나타납니다. RAG 인덱스 로딩 성공 여부 등 추가적인 정보도 로그로 출력됩니다.
3.  서버 실행을 중지하려면, 서버가 실행 중인 터미널에서 `Ctrl+C` 키 조합을 누릅니다.

## 6. 웹 UI 사용

챗봇 서버가 정상적으로 실행 중인 상태에서, 웹 브라우저를 열고 주소창에 아래 URL을 입력하여 접속합니다.

`http://127.0.0.1:8000`

챗봇과 대화할 수 있는 웹 인터페이스가 나타납니다. 하단의 입력창에 메시지를 입력하고 '전송' 버튼을 클릭하거나 Enter 키를 눌러 대화를 시작하세요.

## 7. 설정 변경 (선택 사항)

챗봇의 세부 동작(사용 모델, 프롬프트, RAG 설정 등)은 프로젝트 루트 디렉토리의 `config.yaml` 파일을 수정하여 변경할 수 있습니다.

* 파일 수정 후에는 변경 사항을 적용하기 위해 **챗봇 서버를 재시작**해야 합니다. (`--reload` 옵션 사용 시 자동으로 재시작됩니다.)

## 8. 로그 확인

챗봇 서버 실행 중 발생하는 이벤트 및 오류는 `logs/` 디렉토리에 기록됩니다.

* 주요 로그 파일명은 `api_history.txt` 이며, 날짜별로 로테이션될 수 있습니다.
* 문제 발생 시 로그 파일을 확인하면 원인 파악에 도움이 됩니다. 로그 상세 수준은 `config.yaml`의 `logging.log_level` 설정으로 조절할 수 있습니다.
